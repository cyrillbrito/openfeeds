# Database Package - Drizzle ORM Rules

This package provides the database layer for OpenFeeds using Drizzle ORM with SQLite3.

## Commands

**From root directory:**

```bash
bun user-db-generate   # Generate user database migrations
bun auth-db-generate   # Generate auth database migrations
```

**From packages/db:**

```bash
bun user-db-generate   # Generate user schema migrations only
bun auth-db-generate   # Generate auth schema migrations only
```

## Architecture

**Database Setup:**

- **Primary DB:** SQLite3 for production
- **User Schema:** RSS feeds, articles, tags, read status
- **Auth Schema:** Better Auth tables (users, sessions, etc.)
- **Separate Configs:** `drizzle.config.ts` (user) and `drizzle-auth.config.ts` (auth)

## Schema Management

**User Schema Tables:**

```typescript
// Example table definitions
export const feedsTable = sqliteTable('feeds', {
  id: integer('id').primaryKey({ autoIncrement: true }),
  userId: text('user_id').notNull(),
  url: text('url').notNull(),
  title: text('title'),
  // ...
});

export const articlesTable = sqliteTable('articles', {
  id: integer('id').primaryKey({ autoIncrement: true }),
  feedId: integer('feed_id').references(() => feedsTable.id),
  title: text('title').notNull(),
  // ...
});
```

**Auth Schema:**

- Auto-generated by Better Auth CLI
- Handles users, sessions, accounts tables
- Updated via `bun auth-db-generate` command

## Migration Workflow

**Making Schema Changes:**

1. Modify table definitions in user schema files
2. Run `bun user-db-generate` to create migration files
3. Run `bun migrate` to apply migrations
4. Commit both schema changes and migration files

**Auth Schema Updates:**

1. Update Better Auth configuration in `../../apps/web/src/lib/auth.ts`
2. Run `bun auth-db-generate` to regenerate auth schema
3. Migration files are created automatically
4. Run `bun migrate` to apply changes

**Note:** Migrations are run via the `apps/migrator` app which handles both auth and user database migrations.

## Database Connection

**Connection Patterns:**

```typescript
import { articlesTable, db, feedsTable } from '@repo/db';

// Query with proper typing
const userFeeds = await db.select().from(feedsTable).where(eq(feedsTable.userId, userId));

// Insert with validation
const newFeed = await db
  .insert(feedsTable)
  .values({
    userId,
    url: feedUrl,
    title: feedTitle,
  })
  .returning();
```

## Important Guidelines

- Never modify migration files manually
- Always generate migrations after schema changes
- Test migrations on development database first
- Keep user and auth schemas logically separated
- Use proper TypeScript types from schema exports

## User ID Denormalization (Critical)

**Every table MUST have a `user_id` column with an index.** This includes junction/join tables.

### Why This Is Required

Electric SQL shapes cannot perform JOINs or subqueries in where clauses. Without `user_id` directly on each table:

1. We'd need to build `WHERE id IN (...)` clauses with potentially thousands of IDs
2. This causes HTTP 414 (URI Too Long) errors when URLs exceed browser/server limits
3. Query performance suffers without proper indexing

### Pattern for Junction Tables

```typescript
export const articleTags = pgTable(
  'article_tags',
  {
    id: text('id').primaryKey(),
    // REQUIRED: user_id for Electric SQL filtering
    userId: text('user_id')
      .notNull()
      .references(() => user.id, { onDelete: 'cascade' }),
    articleId: text('article_id')
      .notNull()
      .references(() => articles.id, { onDelete: 'cascade' }),
    tagId: text('tag_id')
      .notNull()
      .references(() => tags.id, { onDelete: 'cascade' }),
  },
  (table) => [
    // REQUIRED: index on user_id for efficient filtering
    index('article_tags_user_id_idx').on(table.userId),
    uniqueIndex('unique_article_tag').on(table.articleId, table.tagId),
    index('article_tags_tag_idx').on(table.tagId),
  ],
);
```

### Checklist for New Tables

- [ ] Add `userId` column with `references(() => user.id, { onDelete: 'cascade' })`
- [ ] Add `index('table_name_user_id_idx').on(table.userId)`
- [ ] Add `user` relation in the relations definition
- [ ] Update shared Zod schemas to include `userId`
- [ ] Update domain functions to pass `userId` on insert
- [ ] Update shape handlers to filter by `user_id`
- [ ] If Electric-synced: Electric automatically manages publications and replica identity in automatic mode. No migration needed.

### Reference

See Electric SQL docs: https://electric-sql.com/docs/guides/shapes#include-tree-workarounds

> "For multi-level include trees, you can denormalise the filtering column onto the lower tables so that you can sync with a simple where clause."

## Electric SQL (Automatic Mode)

Electric SQL runs in automatic mode â€” it manages publications, replica identity, and table subscriptions automatically. Electric connects as the default `postgres` role (which has `REPLICATION` + full data access on PlanetScale). No dedicated `electric_user` or manual publication setup is needed.

## Drizzle Features

- PostgreSQL dialect
- Type-safe queries with InferModel
- Migration system with automatic SQL generation
- Relational queries with joins
